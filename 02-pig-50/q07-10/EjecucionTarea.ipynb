{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigdata\n",
    "!rm -rf output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tabla = LOAD 'data.tsv' USING PigStorage('\\t')\n",
      "    AS (f1:CHARARRAY\n",
      "        ,f2:BAG{t:TUPLE(p:CHARARRAY)}\n",
      "        ,f3:MAP[]\n",
      "        );\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "tabla = LOAD 'data.tsv' USING PigStorage('\\t')\n",
    "    AS (f1:CHARARRAY\n",
    "        ,f2:BAG{t:TUPLE(p:CHARARRAY)}\n",
    "        ,f3:MAP[]\n",
    "        );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y = FOREACH tabla\n",
      "        GENERATE f1 AS letra,\n",
      "        COUNT(f2) AS num_second_column,\n",
      "        SIZE(f3) AS num_map\n",
      ";\n",
      " orden = ORDER y BY letra,num_second_column,num_map;        \n",
      " STORE orden INTO 'output' USING PigStorage(',');\n",
      "2020-01-24 00:14:15,806 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-01-24 00:14:16,418 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2020-01-24 00:14:16,420 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2020-01-24 00:14:16,471 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-24 00:14:16,477 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-01-24 00:14:16,495 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-01-24 00:14:16,705 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-01-24 00:14:16,726 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:16,755 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-01-24 00:14:16,841 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-24 00:14:16,966 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-24 00:14:17,017 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-24 00:14:17,230 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1546411753_0001\n",
      "2020-01-24 00:14:17,659 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579824857387/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 00:14:17,690 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579824857387/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-01-24 00:14:17,691 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579824857387/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 00:14:17,693 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-963080119/tmp384180156/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1579824857387/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 00:14:17,718 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579824857388/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/automaton-1.11-8.jar\n",
      "2020-01-24 00:14:17,725 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579824857388/automaton-1.11-8.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-01-24 00:14:17,725 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579824857388/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/automaton-1.11-8.jar\n",
      "2020-01-24 00:14:17,725 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-963080119/tmp405421959/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1579824857388/automaton-1.11-8.jar\n",
      "2020-01-24 00:14:17,727 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579824857389/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/antlr-runtime-3.4.jar\n",
      "2020-01-24 00:14:17,735 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579824857389/antlr-runtime-3.4.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-01-24 00:14:17,735 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579824857389/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/antlr-runtime-3.4.jar\n",
      "2020-01-24 00:14:17,735 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-963080119/tmp-1858826778/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1579824857389/antlr-runtime-3.4.jar\n",
      "2020-01-24 00:14:17,737 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579824857390/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/joda-time-2.9.3.jar\n",
      "2020-01-24 00:14:17,744 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579824857390/joda-time-2.9.3.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-01-24 00:14:17,744 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579824857390/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/joda-time-2.9.3.jar\n",
      "2020-01-24 00:14:17,744 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-963080119/tmp1080411812/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1579824857390/joda-time-2.9.3.jar\n",
      "2020-01-24 00:14:17,850 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579824857387/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 00:14:17,851 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579824857388/automaton-1.11-8.jar\n",
      "2020-01-24 00:14:17,851 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579824857389/antlr-runtime-3.4.jar\n",
      "2020-01-24 00:14:17,851 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579824857390/joda-time-2.9.3.jar\n",
      "2020-01-24 00:14:17,860 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-01-24 00:14:17,869 [Thread-15] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-01-24 00:14:17,981 [Thread-15] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-24 00:14:17,987 [Thread-15] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 00:14:17,987 [Thread-15] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 00:14:17,988 [Thread-15] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-01-24 00:14:18,063 [Thread-15] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-01-24 00:14:18,065 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1546411753_0001_m_000000_0\n",
      "2020-01-24 00:14:18,195 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 00:14:18,196 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 00:14:18,229 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-24 00:14:18,241 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 1741\n",
      "Input split[0]:\n",
      "   Length = 1741\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-01-24 00:14:18,311 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 00:14:18,311 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 00:14:20,076 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-24 00:14:20,077 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1546411753_0001_m_000000_0 is done. And is in the process of committing\n",
      "2020-01-24 00:14:20,096 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-24 00:14:20,096 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1546411753_0001_m_000000_0 is allowed to commit now\n",
      "2020-01-24 00:14:20,104 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1546411753_0001_m_000000_0' to file:/tmp/temp-963080119/tmp191445258/_temporary/0/task_local1546411753_0001_m_000000\n",
      "2020-01-24 00:14:20,106 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-01-24 00:14:20,107 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1546411753_0001_m_000000_0' done.\n",
      "2020-01-24 00:14:20,114 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1546411753_0001_m_000000_0: Counters: 15\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5803025\n",
      "\t\tFILE: Number of bytes written=12067161\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=40\n",
      "\t\tMap output records=40\n",
      "\t\tInput split bytes=402\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=20\n",
      "\t\tTotal committed heap usage (bytes)=290979840\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-01-24 00:14:20,114 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1546411753_0001_m_000000_0\n",
      "2020-01-24 00:14:20,115 [Thread-15] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-01-24 00:14:22,905 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:22,921 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:22,921 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2020-01-24 00:14:22,921 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-01-24 00:14:22,922 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:23,109 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:23,124 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-24 00:14:23,194 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-24 00:14:23,199 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-24 00:14:23,221 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1281524510_0002\n",
      "2020-01-24 00:14:23,398 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579824863275/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 00:14:23,405 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579824863275/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-01-24 00:14:23,405 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579824863275/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 00:14:23,405 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-963080119/tmp-1102981631/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1579824863275/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 00:14:23,407 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579824863276/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/automaton-1.11-8.jar\n",
      "2020-01-24 00:14:23,413 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579824863276/automaton-1.11-8.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-01-24 00:14:23,413 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579824863276/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/automaton-1.11-8.jar\n",
      "2020-01-24 00:14:23,413 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-963080119/tmp-229957740/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1579824863276/automaton-1.11-8.jar\n",
      "2020-01-24 00:14:23,415 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579824863277/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/antlr-runtime-3.4.jar\n",
      "2020-01-24 00:14:23,421 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579824863277/antlr-runtime-3.4.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-01-24 00:14:23,422 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579824863277/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/antlr-runtime-3.4.jar\n",
      "2020-01-24 00:14:23,422 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-963080119/tmp1894675413/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1579824863277/antlr-runtime-3.4.jar\n",
      "2020-01-24 00:14:23,423 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579824863278/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/joda-time-2.9.3.jar\n",
      "2020-01-24 00:14:23,430 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579824863278/joda-time-2.9.3.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-01-24 00:14:23,430 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579824863278/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/joda-time-2.9.3.jar\n",
      "2020-01-24 00:14:23,430 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-963080119/tmp1340789742/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1579824863278/joda-time-2.9.3.jar\n",
      "2020-01-24 00:14:23,499 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579824863275/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 00:14:23,500 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579824863276/automaton-1.11-8.jar\n",
      "2020-01-24 00:14:23,500 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579824863277/antlr-runtime-3.4.jar\n",
      "2020-01-24 00:14:23,500 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579824863278/joda-time-2.9.3.jar\n",
      "2020-01-24 00:14:23,501 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-01-24 00:14:23,503 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-01-24 00:14:23,523 [Thread-49] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-01-24 00:14:23,524 [Thread-49] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-24 00:14:23,524 [Thread-49] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 00:14:23,524 [Thread-49] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 00:14:23,525 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-01-24 00:14:23,533 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-01-24 00:14:23,533 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1281524510_0002_m_000000_0\n",
      "2020-01-24 00:14:23,560 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 00:14:23,560 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 00:14:23,561 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-24 00:14:23,565 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 480\n",
      "Input split[0]:\n",
      "   Length = 480\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-01-24 00:14:23,972 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-01-24 00:14:23,972 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-01-24 00:14:23,972 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-01-24 00:14:23,972 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-01-24 00:14:23,972 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-01-24 00:14:23,981 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-01-24 00:14:24,027 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-24 00:14:24,027 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-01-24 00:14:24,027 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-01-24 00:14:24,027 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1160; bufvoid = 104857600\n",
      "2020-01-24 00:14:24,027 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214240(104856960); length = 157/6553600\n",
      "2020-01-24 00:14:24,047 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-01-24 00:14:24,053 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1281524510_0002_m_000000_0 is done. And is in the process of committing\n",
      "2020-01-24 00:14:24,058 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-01-24 00:14:24,058 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1281524510_0002_m_000000_0' done.\n",
      "2020-01-24 00:14:24,059 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1281524510_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11604780\n",
      "\t\tFILE: Number of bytes written=24151717\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=40\n",
      "\t\tMap output records=40\n",
      "\t\tMap output bytes=1160\n",
      "\t\tMap output materialized bytes=1246\n",
      "\t\tInput split bytes=377\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=40\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=396361728\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-01-24 00:14:24,060 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1281524510_0002_m_000000_0\n",
      "2020-01-24 00:14:24,060 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-01-24 00:14:24,065 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-01-24 00:14:24,066 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1281524510_0002_r_000000_0\n",
      "2020-01-24 00:14:24,100 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 00:14:24,100 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 00:14:24,105 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-24 00:14:24,116 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5e107ec4\n",
      "2020-01-24 00:14:24,148 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-01-24 00:14:24,155 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1281524510_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-01-24 00:14:24,237 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1281524510_0002_m_000000_0 decomp: 1242 len: 1246 to MEMORY\n",
      "2020-01-24 00:14:24,249 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1242 bytes from map-output for attempt_local1281524510_0002_m_000000_0\n",
      "2020-01-24 00:14:24,252 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1242, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1242\n",
      "2020-01-24 00:14:24,256 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-01-24 00:14:24,258 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-24 00:14:24,258 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-01-24 00:14:24,269 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-24 00:14:24,269 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1222 bytes\n",
      "2020-01-24 00:14:24,272 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1242 bytes to disk to satisfy reduce memory limit\n",
      "2020-01-24 00:14:24,273 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1246 bytes from disk\n",
      "2020-01-24 00:14:24,274 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-01-24 00:14:24,275 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-24 00:14:24,275 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1222 bytes\n",
      "2020-01-24 00:14:24,282 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-24 00:14:24,297 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 00:14:24,297 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 00:14:24,299 [pool-6-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2020-01-24 00:14:24,353 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1281524510_0002_r_000000_0 is done. And is in the process of committing\n",
      "2020-01-24 00:14:24,360 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-24 00:14:24,360 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1281524510_0002_r_000000_0 is allowed to commit now\n",
      "2020-01-24 00:14:24,366 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1281524510_0002_r_000000_0' to file:/tmp/temp-963080119/tmp1795609004/_temporary/0/task_local1281524510_0002_r_000000\n",
      "2020-01-24 00:14:24,368 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-01-24 00:14:24,368 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1281524510_0002_r_000000_0' done.\n",
      "2020-01-24 00:14:24,369 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1281524510_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11607304\n",
      "\t\tFILE: Number of bytes written=24153031\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=1246\n",
      "\t\tReduce input records=40\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=40\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=396361728\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-01-24 00:14:24,369 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1281524510_0002_r_000000_0\n",
      "2020-01-24 00:14:24,369 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-01-24 00:14:29,012 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:29,015 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:29,016 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:29,160 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:29,182 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-24 00:14:29,265 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-24 00:14:29,275 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-24 00:14:29,302 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local919423463_0003\n",
      "2020-01-24 00:14:29,535 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579824869358/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 00:14:29,542 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579824869358/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-01-24 00:14:29,542 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579824869358/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 00:14:29,542 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-963080119/tmp-810195579/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1579824869358/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 00:14:29,543 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579824869359/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/automaton-1.11-8.jar\n",
      "2020-01-24 00:14:29,550 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579824869359/automaton-1.11-8.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-01-24 00:14:29,550 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579824869359/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/automaton-1.11-8.jar\n",
      "2020-01-24 00:14:29,550 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-963080119/tmp-1385765156/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1579824869359/automaton-1.11-8.jar\n",
      "2020-01-24 00:14:29,552 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579824869360/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/antlr-runtime-3.4.jar\n",
      "2020-01-24 00:14:29,559 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579824869360/antlr-runtime-3.4.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-01-24 00:14:29,559 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579824869360/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/antlr-runtime-3.4.jar\n",
      "2020-01-24 00:14:29,559 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-963080119/tmp-2140784025/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1579824869360/antlr-runtime-3.4.jar\n",
      "2020-01-24 00:14:29,560 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579824869361/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/joda-time-2.9.3.jar\n",
      "2020-01-24 00:14:29,567 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579824869361/joda-time-2.9.3.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-01-24 00:14:29,567 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579824869361/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/joda-time-2.9.3.jar\n",
      "2020-01-24 00:14:29,567 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-963080119/tmp1159428670/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1579824869361/joda-time-2.9.3.jar\n",
      "2020-01-24 00:14:29,569 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579824869362/tmp1795609004 <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pigsample_1821335795_1579824869123\n",
      "2020-01-24 00:14:29,575 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579824869362/tmp1795609004 /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pigsample_1821335795_1579824869123' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pigsample_1821335795_1579824869123': Protocol error\n",
      "\n",
      "2020-01-24 00:14:29,576 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579824869362/tmp1795609004 <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/pigsample_1821335795_1579824869123\n",
      "2020-01-24 00:14:29,576 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-963080119/tmp1795609004 as file:/tmp/hadoop-root/mapred/local/1579824869362/tmp1795609004\n",
      "2020-01-24 00:14:29,663 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579824869358/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 00:14:29,663 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579824869359/automaton-1.11-8.jar\n",
      "2020-01-24 00:14:29,663 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579824869360/antlr-runtime-3.4.jar\n",
      "2020-01-24 00:14:29,663 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579824869361/joda-time-2.9.3.jar\n",
      "2020-01-24 00:14:29,664 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-01-24 00:14:29,665 [Thread-88] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-01-24 00:14:29,697 [Thread-88] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-01-24 00:14:29,700 [Thread-88] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-01-24 00:14:29,700 [Thread-88] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-24 00:14:29,700 [Thread-88] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 00:14:29,701 [Thread-88] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 00:14:29,701 [Thread-88] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-01-24 00:14:29,729 [Thread-88] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-01-24 00:14:29,729 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local919423463_0003_m_000000_0\n",
      "2020-01-24 00:14:29,765 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 00:14:29,765 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 00:14:29,766 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-24 00:14:29,774 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 480\n",
      "Input split[0]:\n",
      "   Length = 480\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-01-24 00:14:29,805 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-01-24 00:14:29,805 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-01-24 00:14:29,805 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-01-24 00:14:29,805 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-01-24 00:14:29,805 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-01-24 00:14:29,809 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-01-24 00:14:29,833 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-24 00:14:29,833 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-01-24 00:14:29,833 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-01-24 00:14:29,833 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 560; bufvoid = 104857600\n",
      "2020-01-24 00:14:29,833 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214240(104856960); length = 157/6553600\n",
      "2020-01-24 00:14:29,838 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-01-24 00:14:29,841 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local919423463_0003_m_000000_0 is done. And is in the process of committing\n",
      "2020-01-24 00:14:29,847 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-01-24 00:14:29,848 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local919423463_0003_m_000000_0' done.\n",
      "2020-01-24 00:14:29,848 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local919423463_0003_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17409143\n",
      "\t\tFILE: Number of bytes written=36230416\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=40\n",
      "\t\tMap output records=40\n",
      "\t\tMap output bytes=560\n",
      "\t\tMap output materialized bytes=646\n",
      "\t\tInput split bytes=377\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=40\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=501219328\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-01-24 00:14:29,848 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local919423463_0003_m_000000_0\n",
      "2020-01-24 00:14:29,849 [Thread-88] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-01-24 00:14:29,850 [Thread-88] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-01-24 00:14:29,851 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local919423463_0003_r_000000_0\n",
      "2020-01-24 00:14:29,879 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 00:14:29,879 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 00:14:29,884 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-24 00:14:29,884 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30b2811f\n",
      "2020-01-24 00:14:29,885 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-01-24 00:14:29,889 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local919423463_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-01-24 00:14:29,895 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local919423463_0003_m_000000_0 decomp: 642 len: 646 to MEMORY\n",
      "2020-01-24 00:14:29,897 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 642 bytes from map-output for attempt_local919423463_0003_m_000000_0\n",
      "2020-01-24 00:14:29,898 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 642, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->642\n",
      "2020-01-24 00:14:29,903 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-01-24 00:14:29,906 [Readahead Thread #2] WARN  org.apache.hadoop.io.ReadaheadPool - Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2020-01-24 00:14:29,911 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-24 00:14:29,915 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-01-24 00:14:29,916 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-24 00:14:29,919 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 629 bytes\n",
      "2020-01-24 00:14:29,921 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 642 bytes to disk to satisfy reduce memory limit\n",
      "2020-01-24 00:14:29,922 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 646 bytes from disk\n",
      "2020-01-24 00:14:29,922 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-01-24 00:14:29,922 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-24 00:14:29,922 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 629 bytes\n",
      "2020-01-24 00:14:29,923 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-24 00:14:29,928 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 00:14:29,928 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 00:14:30,074 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local919423463_0003_r_000000_0 is done. And is in the process of committing\n",
      "2020-01-24 00:14:30,095 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-24 00:14:30,096 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local919423463_0003_r_000000_0 is allowed to commit now\n",
      "2020-01-24 00:14:30,141 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local919423463_0003_r_000000_0' to file:/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q07-10/output/_temporary/0/task_local919423463_0003_r_000000\n",
      "2020-01-24 00:14:30,142 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-01-24 00:14:30,144 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local919423463_0003_r_000000_0' done.\n",
      "2020-01-24 00:14:30,145 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local919423463_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17410467\n",
      "\t\tFILE: Number of bytes written=36231314\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=29\n",
      "\t\tReduce shuffle bytes=646\n",
      "\t\tReduce input records=40\n",
      "\t\tReduce output records=40\n",
      "\t\tSpilled Records=40\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=501219328\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-01-24 00:14:30,145 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local919423463_0003_r_000000_0\n",
      "2020-01-24 00:14:30,145 [Thread-88] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-01-24 00:14:34,713 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:34,714 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:34,715 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:34,733 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:34,734 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:34,736 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:34,746 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:34,747 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:34,748 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:34,757 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:34,759 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 00:14:34,760 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "y = FOREACH tabla\n",
    "        GENERATE f1 AS letra,\n",
    "        COUNT(f2) AS num_second_column,\n",
    "        SIZE(f3) AS num_map\n",
    ";\n",
    "orden = ORDER y BY letra,num_second_column,num_map;        \n",
    "STORE orden INTO 'output' USING PigStorage(',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
