{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " u = LOAD 'data.csv' USING PigStorage(',') \n",
      "    AS (id:int, \n",
      "        firstname:CHARARRAY, \n",
      "        surname:CHARARRAY, \n",
      "        birthday:CHARARRAY, \n",
      "        color:CHARARRAY, \n",
      "        quantity:INT);\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "\n",
    "u = LOAD 'data.csv' USING PigStorage(',') \n",
    "    AS (id:int, \n",
    "        firstname:CHARARRAY, \n",
    "        surname:CHARARRAY, \n",
    "        birthday:CHARARRAY, \n",
    "        color:CHARARRAY, \n",
    "        quantity:INT);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --\n",
      " -- >>> Escriba su respuesta a partir de este punto <<<\n",
      " --\n",
      " datos = FILTER(FOREACH u GENERATE firstname, color)\n",
      "        BY REGEX_EXTRACT(color,'(blue|black)',1) IN ('blue','black');\n",
      " STORE datos INTO 'output' USING PigStorage(',');\n",
      "2020-01-24 01:54:25,054 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-01-24 01:54:25,609 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2020-01-24 01:54:25,611 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2020-01-24 01:54:25,663 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-24 01:54:25,669 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-01-24 01:54:25,687 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-01-24 01:54:25,957 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-01-24 01:54:25,983 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:54:26,016 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-01-24 01:54:26,103 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-24 01:54:26,246 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-24 01:54:26,301 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-24 01:54:26,524 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1525498416_0001\n",
      "2020-01-24 01:54:27,024 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579830866718/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:54:27,039 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579830866718/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:54:27,039 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579830866718/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:54:27,039 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1134868458/tmp-356780996/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1579830866718/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:54:27,041 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579830866719/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/automaton-1.11-8.jar\n",
      "2020-01-24 01:54:27,054 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579830866719/automaton-1.11-8.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:54:27,054 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579830866719/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/automaton-1.11-8.jar\n",
      "2020-01-24 01:54:27,054 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1134868458/tmp-848337442/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1579830866719/automaton-1.11-8.jar\n",
      "2020-01-24 01:54:27,056 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579830866720/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:54:27,064 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579830866720/antlr-runtime-3.4.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:54:27,064 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579830866720/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:54:27,064 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1134868458/tmp-668035786/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1579830866720/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:54:27,066 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579830866721/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/joda-time-2.9.3.jar\n",
      "2020-01-24 01:54:27,079 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579830866721/joda-time-2.9.3.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:54:27,079 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579830866721/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/joda-time-2.9.3.jar\n",
      "2020-01-24 01:54:27,079 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1134868458/tmp-1326896996/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1579830866721/joda-time-2.9.3.jar\n",
      "2020-01-24 01:54:27,207 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579830866718/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:54:27,207 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579830866719/automaton-1.11-8.jar\n",
      "2020-01-24 01:54:27,207 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579830866720/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:54:27,207 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579830866721/joda-time-2.9.3.jar\n",
      "2020-01-24 01:54:27,217 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-01-24 01:54:27,229 [Thread-15] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-01-24 01:54:27,328 [Thread-15] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-01-24 01:54:27,331 [Thread-15] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-24 01:54:27,333 [Thread-15] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 01:54:27,333 [Thread-15] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 01:54:27,334 [Thread-15] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-01-24 01:54:27,438 [Thread-15] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-01-24 01:54:27,439 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1525498416_0001_m_000000_0\n",
      "2020-01-24 01:54:27,579 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 01:54:27,579 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 01:54:27,617 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-24 01:54:27,630 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 615\n",
      "Input split[0]:\n",
      "   Length = 615\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-01-24 01:54:27,673 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 01:54:27,673 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 01:54:27,922 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-24 01:54:27,924 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1525498416_0001_m_000000_0 is done. And is in the process of committing\n",
      "2020-01-24 01:54:27,959 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-24 01:54:27,959 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1525498416_0001_m_000000_0 is allowed to commit now\n",
      "2020-01-24 01:54:28,002 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1525498416_0001_m_000000_0' to file:/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q21-10/output/_temporary/0/task_local1525498416_0001_m_000000\n",
      "2020-01-24 01:54:28,005 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-01-24 01:54:28,005 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1525498416_0001_m_000000_0' done.\n",
      "2020-01-24 01:54:28,011 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1525498416_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5801899\n",
      "\t\tFILE: Number of bytes written=12068737\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=5\n",
      "\t\tInput split bytes=402\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=35\n",
      "\t\tTotal committed heap usage (bytes)=290455552\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "\torg.apache.pig.PigWarning\n",
      "\t\tUDF_WARNING_1=26\n",
      "\torg.apache.pig.builtin.REGEX_EXTRACT\n",
      "\t\tUDF_WARNING_1=26\n",
      "2020-01-24 01:54:28,012 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1525498416_0001_m_000000_0\n",
      "2020-01-24 01:54:28,012 [Thread-15] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-01-24 01:54:32,283 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:54:32,303 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:54:32,304 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2020-01-24 01:54:32,304 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-01-24 01:54:32,306 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:54:32,364 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:54:32,365 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:54:32,366 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "\n",
    "--\n",
    "-- >>> Escriba su respuesta a partir de este punto <<<\n",
    "--\n",
    "datos = FILTER(FOREACH u GENERATE firstname, color)\n",
    "        BY REGEX_EXTRACT(color,'(blue|green)',1) IN ('blue','green');\n",
    "\n",
    "STORE datos INTO 'output' USING PigStorage('\\t');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
