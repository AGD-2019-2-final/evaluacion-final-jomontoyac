{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bigdata extension is already loaded. To reload it, use:\n",
      "  %reload_ext bigdata\n"
     ]
    }
   ],
   "source": [
    "%load_ext bigdata\n",
    "!rm -rf output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " u = LOAD 'truck_event_text_partition.csv' USING PigStorage(',')\n",
      "    AS (driverId:INT,\n",
      "        truckId:INT,\n",
      "        eventTime:CHARARRAY,\n",
      "        eventType:CHARARRAY,\n",
      "        longitude:DOUBLE,\n",
      "        latitude:DOUBLE,\n",
      "        eventKey:CHARARRAY,\n",
      "        correlationId:CHARARRAY,\n",
      "        driverName:CHARARRAY,\n",
      "        routeId:BIGINTEGER,\n",
      "        routeName:CHARARRAY,\n",
      "        eventDate:CHARARRAY\n",
      "        );\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "u = LOAD 'truck_event_text_partition.csv' USING PigStorage(',')\n",
    "    AS (driverId:INT,\n",
    "        truckId:INT,\n",
    "        eventTime:CHARARRAY,\n",
    "        eventType:CHARARRAY,\n",
    "        longitude:DOUBLE,\n",
    "        latitude:DOUBLE,\n",
    "        eventKey:CHARARRAY,\n",
    "        correlationId:CHARARRAY,\n",
    "        driverName:CHARARRAY,\n",
    "        routeId:BIGINTEGER,\n",
    "        routeName:CHARARRAY,\n",
    "        eventDate:CHARARRAY\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " z = FOREACH (LIMIT u 10) GENERATE $0,$1,$2;\n",
      " y = ORDER z BY $0,$1,$2;\n",
      " STORE y INTO 'output' USING PigStorage(',');\n",
      "2020-01-23 02:48:20,447 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:20,505 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:20,510 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-23 02:48:20,565 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-23 02:48:20,570 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-23 02:48:20,586 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local497721349_0009\n",
      "2020-01-23 02:48:20,800 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747700666/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:20,807 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747700666/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:20,807 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747700666/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:20,807 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp1992638055/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1579747700666/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:20,809 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747700667/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:20,816 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747700667/automaton-1.11-8.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:20,816 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747700667/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:20,816 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp-1682012509/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1579747700667/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:20,818 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747700668/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:20,825 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747700668/antlr-runtime-3.4.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:20,825 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747700668/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:20,825 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp-780890111/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1579747700668/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:20,826 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747700669/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:20,833 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747700669/joda-time-2.9.3.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:20,833 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747700669/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:20,833 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp930188108/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1579747700669/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:21,013 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747700666/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:21,013 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747700667/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:21,013 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747700668/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:21,013 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747700669/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:21,014 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-01-23 02:48:21,014 [Thread-329] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-01-23 02:48:21,027 [Thread-329] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-01-23 02:48:21,027 [Thread-329] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-23 02:48:21,027 [Thread-329] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:21,027 [Thread-329] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:21,028 [Thread-329] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-01-23 02:48:21,049 [Thread-329] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-01-23 02:48:21,049 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local497721349_0009_m_000000_0\n",
      "2020-01-23 02:48:21,067 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:21,067 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:21,067 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-23 02:48:21,088 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 2271958\n",
      "Input split[0]:\n",
      "   Length = 2271958\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-01-23 02:48:21,173 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-01-23 02:48:21,173 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-01-23 02:48:21,173 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-01-23 02:48:21,173 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-01-23 02:48:21,173 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-01-23 02:48:21,174 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-01-23 02:48:21,215 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-23 02:48:21,215 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-01-23 02:48:21,215 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-01-23 02:48:21,215 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 231; bufvoid = 104857600\n",
      "2020-01-23 02:48:21,216 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600\n",
      "2020-01-23 02:48:21,217 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-01-23 02:48:21,219 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local497721349_0009_m_000000_0 is done. And is in the process of committing\n",
      "2020-01-23 02:48:21,223 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-01-23 02:48:21,223 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local497721349_0009_m_000000_0' done.\n",
      "2020-01-23 02:48:21,223 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local497721349_0009_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=52230136\n",
      "\t\tFILE: Number of bytes written=108701697\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10\n",
      "\t\tMap output records=10\n",
      "\t\tMap output bytes=231\n",
      "\t\tMap output materialized bytes=257\n",
      "\t\tInput split bytes=424\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=10\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=67\n",
      "\t\tTotal committed heap usage (bytes)=468189184\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-01-23 02:48:21,223 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local497721349_0009_m_000000_0\n",
      "2020-01-23 02:48:21,224 [Thread-329] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-01-23 02:48:21,225 [Thread-329] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-01-23 02:48:21,226 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local497721349_0009_r_000000_0\n",
      "2020-01-23 02:48:21,242 [pool-30-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:21,242 [pool-30-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:21,244 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-23 02:48:21,244 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7c982386\n",
      "2020-01-23 02:48:21,245 [pool-30-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-01-23 02:48:21,248 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local497721349_0009_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-01-23 02:48:21,250 [localfetcher#9] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#9 about to shuffle output of map attempt_local497721349_0009_m_000000_0 decomp: 253 len: 257 to MEMORY\n",
      "2020-01-23 02:48:21,250 [localfetcher#9] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 253 bytes from map-output for attempt_local497721349_0009_m_000000_0\n",
      "2020-01-23 02:48:21,251 [localfetcher#9] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 253, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->253\n",
      "2020-01-23 02:48:21,252 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-01-23 02:48:21,262 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-23 02:48:21,262 [pool-30-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-01-23 02:48:21,264 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-23 02:48:21,264 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 231 bytes\n",
      "2020-01-23 02:48:21,266 [pool-30-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 253 bytes to disk to satisfy reduce memory limit\n",
      "2020-01-23 02:48:21,266 [pool-30-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 257 bytes from disk\n",
      "2020-01-23 02:48:21,266 [pool-30-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-01-23 02:48:21,266 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-23 02:48:21,267 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 231 bytes\n",
      "2020-01-23 02:48:21,268 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-23 02:48:21,270 [pool-30-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:21,270 [pool-30-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:21,278 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local497721349_0009_r_000000_0 is done. And is in the process of committing\n",
      "2020-01-23 02:48:21,281 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-23 02:48:21,281 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local497721349_0009_r_000000_0 is allowed to commit now\n",
      "2020-01-23 02:48:21,289 [pool-30-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local497721349_0009_r_000000_0' to file:/tmp/temp742605088/tmp-484989358/_temporary/0/task_local497721349_0009_r_000000\n",
      "2020-01-23 02:48:21,290 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-01-23 02:48:21,290 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local497721349_0009_r_000000_0' done.\n",
      "2020-01-23 02:48:21,290 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local497721349_0009_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=52230682\n",
      "\t\tFILE: Number of bytes written=108702177\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce shuffle bytes=257\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=10\n",
      "\t\tSpilled Records=10\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=468189184\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-01-23 02:48:21,290 [pool-30-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local497721349_0009_r_000000_0\n",
      "2020-01-23 02:48:21,291 [Thread-329] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-01-23 02:48:26,059 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:26,061 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:26,062 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:26,177 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:26,181 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-23 02:48:26,233 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-23 02:48:26,236 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-23 02:48:26,252 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local101272883_0010\n",
      "2020-01-23 02:48:26,434 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747706295/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:26,440 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747706295/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:26,440 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747706295/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:26,440 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp947405333/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1579747706295/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:26,442 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747706296/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:26,448 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747706296/automaton-1.11-8.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:26,449 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747706296/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:26,449 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp568589911/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1579747706296/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:26,450 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747706297/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:26,456 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747706297/antlr-runtime-3.4.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:26,456 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747706297/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:26,456 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp-373154879/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1579747706297/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:26,457 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747706298/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:26,463 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747706298/joda-time-2.9.3.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:26,463 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747706298/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:26,463 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp-270282104/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1579747706298/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:26,518 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747706295/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:26,518 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747706296/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:26,518 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747706297/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:26,518 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747706298/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:26,519 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-01-23 02:48:26,519 [Thread-367] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-01-23 02:48:26,529 [Thread-367] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-01-23 02:48:26,529 [Thread-367] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-23 02:48:26,529 [Thread-367] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:26,529 [Thread-367] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:26,529 [Thread-367] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-01-23 02:48:26,533 [Thread-367] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-01-23 02:48:26,534 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local101272883_0010_m_000000_0\n",
      "2020-01-23 02:48:26,551 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:26,551 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:26,551 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-23 02:48:26,554 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 211\n",
      "Input split[0]:\n",
      "   Length = 211\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-01-23 02:48:26,629 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-01-23 02:48:26,630 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-01-23 02:48:26,630 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-01-23 02:48:26,630 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-01-23 02:48:26,630 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-01-23 02:48:26,631 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-01-23 02:48:26,635 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-23 02:48:26,635 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-01-23 02:48:26,635 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-01-23 02:48:26,635 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 231; bufvoid = 104857600\n",
      "2020-01-23 02:48:26,635 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600\n",
      "2020-01-23 02:48:26,638 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-01-23 02:48:26,640 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local101272883_0010_m_000000_0 is done. And is in the process of committing\n",
      "2020-01-23 02:48:26,644 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-01-23 02:48:26,644 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local101272883_0010_m_000000_0' done.\n",
      "2020-01-23 02:48:26,644 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local101272883_0010_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=58032167\n",
      "\t\tFILE: Number of bytes written=120780352\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10\n",
      "\t\tMap output records=10\n",
      "\t\tMap output bytes=231\n",
      "\t\tMap output materialized bytes=257\n",
      "\t\tInput split bytes=377\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=10\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=57\n",
      "\t\tTotal committed heap usage (bytes)=504889344\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-01-23 02:48:26,645 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local101272883_0010_m_000000_0\n",
      "2020-01-23 02:48:26,645 [Thread-367] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-01-23 02:48:26,647 [Thread-367] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-01-23 02:48:26,647 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local101272883_0010_r_000000_0\n",
      "2020-01-23 02:48:26,661 [pool-33-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:26,661 [pool-33-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:26,663 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-23 02:48:26,663 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@32caef1d\n",
      "2020-01-23 02:48:26,664 [pool-33-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-01-23 02:48:26,665 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local101272883_0010_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-01-23 02:48:26,670 [localfetcher#10] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#10 about to shuffle output of map attempt_local101272883_0010_m_000000_0 decomp: 253 len: 257 to MEMORY\n",
      "2020-01-23 02:48:26,670 [localfetcher#10] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 253 bytes from map-output for attempt_local101272883_0010_m_000000_0\n",
      "2020-01-23 02:48:26,670 [localfetcher#10] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 253, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->253\n",
      "2020-01-23 02:48:26,671 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-01-23 02:48:26,672 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-23 02:48:26,672 [pool-33-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-01-23 02:48:26,674 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-23 02:48:26,674 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 231 bytes\n",
      "2020-01-23 02:48:26,675 [pool-33-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 253 bytes to disk to satisfy reduce memory limit\n",
      "2020-01-23 02:48:26,675 [pool-33-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 257 bytes from disk\n",
      "2020-01-23 02:48:26,675 [pool-33-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-01-23 02:48:26,675 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-23 02:48:26,676 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 231 bytes\n",
      "2020-01-23 02:48:26,676 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-23 02:48:26,678 [pool-33-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:26,678 [pool-33-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:26,694 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local101272883_0010_r_000000_0 is done. And is in the process of committing\n",
      "2020-01-23 02:48:26,696 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-23 02:48:26,696 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local101272883_0010_r_000000_0 is allowed to commit now\n",
      "2020-01-23 02:48:26,698 [pool-33-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local101272883_0010_r_000000_0' to file:/tmp/temp742605088/tmp1114669165/_temporary/0/task_local101272883_0010_r_000000\n",
      "2020-01-23 02:48:26,699 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-01-23 02:48:26,699 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local101272883_0010_r_000000_0' done.\n",
      "2020-01-23 02:48:26,700 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local101272883_0010_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=58032713\n",
      "\t\tFILE: Number of bytes written=120780801\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce shuffle bytes=257\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=10\n",
      "\t\tSpilled Records=10\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=504889344\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-01-23 02:48:26,700 [pool-33-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local101272883_0010_r_000000_0\n",
      "2020-01-23 02:48:26,700 [Thread-367] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-01-23 02:48:31,694 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:31,696 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:31,697 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:31,826 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:31,830 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-23 02:48:31,883 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-23 02:48:31,886 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-23 02:48:31,900 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local785812844_0011\n",
      "2020-01-23 02:48:32,089 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747711942/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:32,095 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747711942/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:32,095 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747711942/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:32,095 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp1851281348/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1579747711942/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:32,097 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747711943/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:32,102 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747711943/automaton-1.11-8.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:32,102 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747711943/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:32,102 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp-575077205/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1579747711943/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:32,104 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747711944/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:32,109 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747711944/antlr-runtime-3.4.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:32,109 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747711944/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:32,109 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp-746382493/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1579747711944/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:32,110 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747711945/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:32,116 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747711945/joda-time-2.9.3.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:32,116 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747711945/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:32,116 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp1140678093/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1579747711945/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:32,177 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747711942/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:32,177 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747711943/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:32,177 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747711944/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:32,177 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747711945/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:32,177 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-01-23 02:48:32,178 [Thread-405] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-01-23 02:48:32,188 [Thread-405] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-01-23 02:48:32,188 [Thread-405] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-23 02:48:32,188 [Thread-405] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:32,188 [Thread-405] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:32,189 [Thread-405] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-01-23 02:48:32,192 [Thread-405] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-01-23 02:48:32,192 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local785812844_0011_m_000000_0\n",
      "2020-01-23 02:48:32,210 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:32,210 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:32,210 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-23 02:48:32,216 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 180\n",
      "Input split[0]:\n",
      "   Length = 180\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-01-23 02:48:32,507 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-01-23 02:48:32,507 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-01-23 02:48:32,507 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-01-23 02:48:32,507 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-01-23 02:48:32,508 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-01-23 02:48:32,509 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-01-23 02:48:32,522 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-23 02:48:32,522 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-01-23 02:48:32,522 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-01-23 02:48:32,522 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 410; bufvoid = 104857600\n",
      "2020-01-23 02:48:32,522 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600\n",
      "2020-01-23 02:48:32,542 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-01-23 02:48:32,543 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local785812844_0011_m_000000_0 is done. And is in the process of committing\n",
      "2020-01-23 02:48:32,548 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-01-23 02:48:32,548 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local785812844_0011_m_000000_0' done.\n",
      "2020-01-23 02:48:32,548 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local785812844_0011_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=63834167\n",
      "\t\tFILE: Number of bytes written=132861825\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10\n",
      "\t\tMap output records=10\n",
      "\t\tMap output bytes=410\n",
      "\t\tMap output materialized bytes=436\n",
      "\t\tInput split bytes=377\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=10\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=504889344\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-01-23 02:48:32,548 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local785812844_0011_m_000000_0\n",
      "2020-01-23 02:48:32,548 [Thread-405] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-01-23 02:48:32,550 [Thread-405] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-01-23 02:48:32,551 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local785812844_0011_r_000000_0\n",
      "2020-01-23 02:48:32,564 [pool-36-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:32,564 [pool-36-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:32,566 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-23 02:48:32,566 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@148c7e7b\n",
      "2020-01-23 02:48:32,568 [pool-36-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-01-23 02:48:32,570 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local785812844_0011_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-01-23 02:48:32,576 [localfetcher#11] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#11 about to shuffle output of map attempt_local785812844_0011_m_000000_0 decomp: 432 len: 436 to MEMORY\n",
      "2020-01-23 02:48:32,576 [localfetcher#11] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 432 bytes from map-output for attempt_local785812844_0011_m_000000_0\n",
      "2020-01-23 02:48:32,576 [Readahead Thread #0] WARN  org.apache.hadoop.io.ReadaheadPool - Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2020-01-23 02:48:32,577 [localfetcher#11] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 432, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->432\n",
      "2020-01-23 02:48:32,578 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-01-23 02:48:32,579 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-23 02:48:32,579 [pool-36-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-01-23 02:48:32,581 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-23 02:48:32,581 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 406 bytes\n",
      "2020-01-23 02:48:32,582 [pool-36-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 432 bytes to disk to satisfy reduce memory limit\n",
      "2020-01-23 02:48:32,582 [pool-36-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 436 bytes from disk\n",
      "2020-01-23 02:48:32,582 [pool-36-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-01-23 02:48:32,582 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-23 02:48:32,583 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 406 bytes\n",
      "2020-01-23 02:48:32,583 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-23 02:48:32,585 [pool-36-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:32,585 [pool-36-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:32,623 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local785812844_0011_r_000000_0 is done. And is in the process of committing\n",
      "2020-01-23 02:48:32,626 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-23 02:48:32,626 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local785812844_0011_r_000000_0 is allowed to commit now\n",
      "2020-01-23 02:48:32,628 [pool-36-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local785812844_0011_r_000000_0' to file:/tmp/temp742605088/tmp576111255/_temporary/0/task_local785812844_0011_r_000000\n",
      "2020-01-23 02:48:32,629 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-01-23 02:48:32,629 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local785812844_0011_r_000000_0' done.\n",
      "2020-01-23 02:48:32,630 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local785812844_0011_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=63835071\n",
      "\t\tFILE: Number of bytes written=132862335\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=436\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=10\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=504889344\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-01-23 02:48:32,630 [pool-36-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local785812844_0011_r_000000_0\n",
      "2020-01-23 02:48:32,633 [Thread-405] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-01-23 02:48:37,518 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:37,520 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:37,522 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:37,616 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:37,623 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-23 02:48:37,716 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-23 02:48:37,718 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-23 02:48:37,733 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1680614493_0012\n",
      "2020-01-23 02:48:37,960 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747717778/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:37,967 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747717778/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:37,967 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747717778/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:37,967 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp-734803042/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1579747717778/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:37,969 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747717779/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:37,976 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747717779/automaton-1.11-8.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:37,976 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747717779/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:37,976 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp2004716538/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1579747717779/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:37,978 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747717780/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:37,985 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747717780/antlr-runtime-3.4.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:37,985 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747717780/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:37,985 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp441836445/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1579747717780/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:37,986 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747717781/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:37,993 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747717781/joda-time-2.9.3.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-01-23 02:48:37,993 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747717781/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:37,993 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp1076860476/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1579747717781/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:37,994 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579747717782/tmp576111255 <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pigsample_1709493124_1579747717602\n",
      "2020-01-23 02:48:38,002 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579747717782/tmp576111255 /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pigsample_1709493124_1579747717602' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pigsample_1709493124_1579747717602': Protocol error\n",
      "\n",
      "2020-01-23 02:48:38,002 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579747717782/tmp576111255 <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/pigsample_1709493124_1579747717602\n",
      "2020-01-23 02:48:38,002 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp742605088/tmp576111255 as file:/tmp/hadoop-root/mapred/local/1579747717782/tmp576111255\n",
      "2020-01-23 02:48:38,060 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747717778/pig-0.17.0-core-h2.jar\n",
      "2020-01-23 02:48:38,060 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747717779/automaton-1.11-8.jar\n",
      "2020-01-23 02:48:38,060 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747717780/antlr-runtime-3.4.jar\n",
      "2020-01-23 02:48:38,060 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579747717781/joda-time-2.9.3.jar\n",
      "2020-01-23 02:48:38,061 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-01-23 02:48:38,061 [Thread-444] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-01-23 02:48:38,077 [Thread-444] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-01-23 02:48:38,077 [Thread-444] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-01-23 02:48:38,078 [Thread-444] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-23 02:48:38,078 [Thread-444] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:38,078 [Thread-444] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:38,078 [Thread-444] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-01-23 02:48:38,106 [Thread-444] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-01-23 02:48:38,106 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1680614493_0012_m_000000_0\n",
      "2020-01-23 02:48:38,124 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:38,124 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:38,124 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-23 02:48:38,126 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 180\n",
      "Input split[0]:\n",
      "   Length = 180\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-01-23 02:48:38,143 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-01-23 02:48:38,143 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-01-23 02:48:38,143 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-01-23 02:48:38,143 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-01-23 02:48:38,143 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-01-23 02:48:38,144 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-01-23 02:48:38,153 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-23 02:48:38,153 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-01-23 02:48:38,153 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-01-23 02:48:38,153 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 200; bufvoid = 104857600\n",
      "2020-01-23 02:48:38,153 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600\n",
      "2020-01-23 02:48:38,156 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-01-23 02:48:38,157 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1680614493_0012_m_000000_0 is done. And is in the process of committing\n",
      "2020-01-23 02:48:38,163 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-01-23 02:48:38,163 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1680614493_0012_m_000000_0' done.\n",
      "2020-01-23 02:48:38,163 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1680614493_0012_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=69636615\n",
      "\t\tFILE: Number of bytes written=144940561\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10\n",
      "\t\tMap output records=10\n",
      "\t\tMap output bytes=200\n",
      "\t\tMap output materialized bytes=226\n",
      "\t\tInput split bytes=377\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=10\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=504889344\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-01-23 02:48:38,163 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1680614493_0012_m_000000_0\n",
      "2020-01-23 02:48:38,164 [Thread-444] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-01-23 02:48:38,165 [Thread-444] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-01-23 02:48:38,166 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1680614493_0012_r_000000_0\n",
      "2020-01-23 02:48:38,181 [pool-39-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:38,182 [pool-39-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:38,183 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-23 02:48:38,183 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@36d2352d\n",
      "2020-01-23 02:48:38,184 [pool-39-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-01-23 02:48:38,187 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1680614493_0012_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-01-23 02:48:38,190 [localfetcher#12] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#12 about to shuffle output of map attempt_local1680614493_0012_m_000000_0 decomp: 222 len: 226 to MEMORY\n",
      "2020-01-23 02:48:38,191 [localfetcher#12] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 222 bytes from map-output for attempt_local1680614493_0012_m_000000_0\n",
      "2020-01-23 02:48:38,191 [localfetcher#12] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 222, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->222\n",
      "2020-01-23 02:48:38,192 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-01-23 02:48:38,193 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-23 02:48:38,193 [pool-39-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-01-23 02:48:38,194 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-23 02:48:38,195 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 203 bytes\n",
      "2020-01-23 02:48:38,196 [pool-39-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 222 bytes to disk to satisfy reduce memory limit\n",
      "2020-01-23 02:48:38,196 [pool-39-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 226 bytes from disk\n",
      "2020-01-23 02:48:38,196 [pool-39-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-01-23 02:48:38,196 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-23 02:48:38,197 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 203 bytes\n",
      "2020-01-23 02:48:38,197 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-23 02:48:38,199 [pool-39-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-23 02:48:38,199 [pool-39-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-23 02:48:38,342 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1680614493_0012_r_000000_0 is done. And is in the process of committing\n",
      "2020-01-23 02:48:38,358 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-23 02:48:38,358 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1680614493_0012_r_000000_0 is allowed to commit now\n",
      "2020-01-23 02:48:38,391 [pool-39-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1680614493_0012_r_000000_0' to file:/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q04-10/output/_temporary/0/task_local1680614493_0012_r_000000\n",
      "2020-01-23 02:48:38,393 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-01-23 02:48:38,393 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1680614493_0012_r_000000_0' done.\n",
      "2020-01-23 02:48:38,393 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1680614493_0012_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=69637099\n",
      "\t\tFILE: Number of bytes written=144940940\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce shuffle bytes=226\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=10\n",
      "\t\tSpilled Records=10\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=504889344\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-01-23 02:48:38,393 [pool-39-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1680614493_0012_r_000000_0\n",
      "2020-01-23 02:48:38,393 [Thread-444] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-01-23 02:48:43,136 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:43,137 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:43,138 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:43,151 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:43,152 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:43,154 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:43,159 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:43,161 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:43,162 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:43,165 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:43,167 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:43,168 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:43,172 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:43,173 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-23 02:48:43,174 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "z = FOREACH (LIMIT u 10) GENERATE $0,$1,$2;\n",
    "y = ORDER z BY $0,$1,$2;\n",
    "STORE y INTO 'output' USING PigStorage(',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
