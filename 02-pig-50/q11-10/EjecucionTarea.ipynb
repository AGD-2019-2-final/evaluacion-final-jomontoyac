{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " u = LOAD 'data.csv' USING PigStorage(',') \n",
      "    AS (id:int, \n",
      "        firstname:CHARARRAY, \n",
      "        surname:CHARARRAY, \n",
      "        birthday:CHARARRAY, \n",
      "        color:CHARARRAY, \n",
      "        quantity:INT);\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "u = LOAD 'data.csv' USING PigStorage(',') \n",
    "    AS (id:int, \n",
    "        firstname:CHARARRAY, \n",
    "        surname:CHARARRAY, \n",
    "        birthday:CHARARRAY, \n",
    "        color:CHARARRAY, \n",
    "        quantity:INT);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " estilos = FOREACH u GENERATE surname AS apellido,\n",
      "                    UPPER(surname) AS mayuscula,\n",
      "                    LOWER(surname) AS minuscula\n",
      ";\n",
      " orden = ORDER estilos BY apellido ASC, mayuscula ASC, minuscula ASC;\n",
      " STORE orden INTO 'output' USING PigStorage(',');\n",
      "2020-01-24 01:17:03,257 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:03,369 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:03,387 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-24 01:17:03,459 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-24 01:17:03,465 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-24 01:17:03,492 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local321855304_0002\n",
      "2020-01-24 01:17:03,670 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579828623543/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:17:03,676 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579828623543/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:17:03,677 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579828623543/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:17:03,677 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1534593231/tmp-1653029553/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1579828623543/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:17:03,678 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579828623544/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/automaton-1.11-8.jar\n",
      "2020-01-24 01:17:03,687 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579828623544/automaton-1.11-8.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:17:03,687 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579828623544/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/automaton-1.11-8.jar\n",
      "2020-01-24 01:17:03,687 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1534593231/tmp2133904137/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1579828623544/automaton-1.11-8.jar\n",
      "2020-01-24 01:17:03,689 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579828623545/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:17:03,696 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579828623545/antlr-runtime-3.4.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:17:03,696 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579828623545/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:17:03,696 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1534593231/tmp772317122/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1579828623545/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:17:03,698 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579828623546/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/joda-time-2.9.3.jar\n",
      "2020-01-24 01:17:03,708 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579828623546/joda-time-2.9.3.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:17:03,708 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579828623546/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/joda-time-2.9.3.jar\n",
      "2020-01-24 01:17:03,708 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1534593231/tmp620283075/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1579828623546/joda-time-2.9.3.jar\n",
      "2020-01-24 01:17:03,778 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579828623543/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:17:03,778 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579828623544/automaton-1.11-8.jar\n",
      "2020-01-24 01:17:03,778 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579828623545/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:17:03,778 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579828623546/joda-time-2.9.3.jar\n",
      "2020-01-24 01:17:03,779 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-01-24 01:17:03,780 [Thread-47] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-01-24 01:17:03,800 [Thread-47] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-24 01:17:03,801 [Thread-47] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 01:17:03,801 [Thread-47] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 01:17:03,802 [Thread-47] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-01-24 01:17:03,810 [Thread-47] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-01-24 01:17:03,813 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local321855304_0002_m_000000_0\n",
      "2020-01-24 01:17:03,841 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 01:17:03,841 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 01:17:03,846 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-24 01:17:03,851 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 615\n",
      "Input split[0]:\n",
      "   Length = 615\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-01-24 01:17:03,884 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 01:17:03,884 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 01:17:03,932 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-24 01:17:03,933 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local321855304_0002_m_000000_0 is done. And is in the process of committing\n",
      "2020-01-24 01:17:03,942 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-24 01:17:03,943 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local321855304_0002_m_000000_0 is allowed to commit now\n",
      "2020-01-24 01:17:03,948 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local321855304_0002_m_000000_0' to file:/tmp/temp1534593231/tmp-132105597/_temporary/0/task_local321855304_0002_m_000000\n",
      "2020-01-24 01:17:03,950 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-01-24 01:17:03,950 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local321855304_0002_m_000000_0' done.\n",
      "2020-01-24 01:17:03,951 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local321855304_0002_m_000000_0: Counters: 15\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11603798\n",
      "\t\tFILE: Number of bytes written=24131766\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tInput split bytes=402\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=292028416\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-01-24 01:17:03,952 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local321855304_0002_m_000000_0\n",
      "2020-01-24 01:17:03,952 [Thread-47] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-01-24 01:17:08,894 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:08,897 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:08,900 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:09,019 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:09,028 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-24 01:17:09,116 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-24 01:17:09,119 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-24 01:17:09,163 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1678015357_0003\n",
      "2020-01-24 01:17:09,353 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579828629225/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:17:09,360 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579828629225/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:17:09,360 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579828629225/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:17:09,360 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1534593231/tmp1683246963/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1579828629225/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:17:09,362 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579828629226/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/automaton-1.11-8.jar\n",
      "2020-01-24 01:17:09,369 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579828629226/automaton-1.11-8.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:17:09,369 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579828629226/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/automaton-1.11-8.jar\n",
      "2020-01-24 01:17:09,369 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1534593231/tmp-1566318614/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1579828629226/automaton-1.11-8.jar\n",
      "2020-01-24 01:17:09,370 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579828629227/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:17:09,377 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579828629227/antlr-runtime-3.4.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:17:09,377 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579828629227/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:17:09,377 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1534593231/tmp-1139196845/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1579828629227/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:17:09,379 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579828629228/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/joda-time-2.9.3.jar\n",
      "2020-01-24 01:17:09,386 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579828629228/joda-time-2.9.3.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:17:09,386 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579828629228/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/joda-time-2.9.3.jar\n",
      "2020-01-24 01:17:09,386 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1534593231/tmp-327946805/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1579828629228/joda-time-2.9.3.jar\n",
      "2020-01-24 01:17:09,446 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579828629225/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:17:09,446 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579828629226/automaton-1.11-8.jar\n",
      "2020-01-24 01:17:09,447 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579828629227/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:17:09,447 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579828629228/joda-time-2.9.3.jar\n",
      "2020-01-24 01:17:09,447 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-01-24 01:17:09,448 [Thread-79] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-01-24 01:17:09,470 [Thread-79] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-01-24 01:17:09,471 [Thread-79] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-24 01:17:09,471 [Thread-79] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 01:17:09,471 [Thread-79] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 01:17:09,472 [Thread-79] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-01-24 01:17:09,480 [Thread-79] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-01-24 01:17:09,480 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1678015357_0003_m_000000_0\n",
      "2020-01-24 01:17:09,506 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 01:17:09,506 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 01:17:09,507 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-24 01:17:09,510 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 525\n",
      "Input split[0]:\n",
      "   Length = 525\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-01-24 01:17:09,572 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-01-24 01:17:09,572 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-01-24 01:17:09,572 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-01-24 01:17:09,572 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-01-24 01:17:09,572 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-01-24 01:17:09,586 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-01-24 01:17:09,629 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-24 01:17:09,629 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-01-24 01:17:09,629 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-01-24 01:17:09,629 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1140; bufvoid = 104857600\n",
      "2020-01-24 01:17:09,629 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600\n",
      "2020-01-24 01:17:09,642 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-01-24 01:17:09,648 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1678015357_0003_m_000000_0 is done. And is in the process of committing\n",
      "2020-01-24 01:17:09,654 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-01-24 01:17:09,654 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1678015357_0003_m_000000_0' done.\n",
      "2020-01-24 01:17:09,655 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1678015357_0003_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17405603\n",
      "\t\tFILE: Number of bytes written=36216757\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tMap output bytes=1140\n",
      "\t\tMap output materialized bytes=1182\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=18\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=383254528\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-01-24 01:17:09,655 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1678015357_0003_m_000000_0\n",
      "2020-01-24 01:17:09,655 [Thread-79] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-01-24 01:17:09,659 [Thread-79] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-01-24 01:17:09,660 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1678015357_0003_r_000000_0\n",
      "2020-01-24 01:17:09,687 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 01:17:09,687 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 01:17:09,691 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-24 01:17:09,695 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6a13374c\n",
      "2020-01-24 01:17:09,718 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-01-24 01:17:09,722 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1678015357_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-01-24 01:17:09,785 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1678015357_0003_m_000000_0 decomp: 1178 len: 1182 to MEMORY\n",
      "2020-01-24 01:17:09,790 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1178 bytes from map-output for attempt_local1678015357_0003_m_000000_0\n",
      "2020-01-24 01:17:09,793 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1178, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1178\n",
      "2020-01-24 01:17:09,797 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-01-24 01:17:09,799 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-24 01:17:09,799 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-01-24 01:17:09,810 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-24 01:17:09,810 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1142 bytes\n",
      "2020-01-24 01:17:09,813 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1178 bytes to disk to satisfy reduce memory limit\n",
      "2020-01-24 01:17:09,813 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1182 bytes from disk\n",
      "2020-01-24 01:17:09,814 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-01-24 01:17:09,814 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-24 01:17:09,815 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1142 bytes\n",
      "2020-01-24 01:17:09,816 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-24 01:17:09,825 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 01:17:09,825 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 01:17:09,827 [pool-8-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2020-01-24 01:17:09,859 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1678015357_0003_r_000000_0 is done. And is in the process of committing\n",
      "2020-01-24 01:17:09,864 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-24 01:17:09,865 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1678015357_0003_r_000000_0 is allowed to commit now\n",
      "2020-01-24 01:17:09,869 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1678015357_0003_r_000000_0' to file:/tmp/temp1534593231/tmp686736939/_temporary/0/task_local1678015357_0003_r_000000\n",
      "2020-01-24 01:17:09,872 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-01-24 01:17:09,872 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1678015357_0003_r_000000_0' done.\n",
      "2020-01-24 01:17:09,873 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1678015357_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17407999\n",
      "\t\tFILE: Number of bytes written=36218023\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=1182\n",
      "\t\tReduce input records=18\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=18\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=383254528\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-01-24 01:17:09,873 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1678015357_0003_r_000000_0\n",
      "2020-01-24 01:17:09,873 [Thread-79] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-01-24 01:17:14,540 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:14,542 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:14,543 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:14,638 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:14,652 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-24 01:17:14,715 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-24 01:17:14,720 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-24 01:17:14,743 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1414629484_0004\n",
      "2020-01-24 01:17:14,941 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579828634796/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:17:14,947 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579828634796/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:17:14,947 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579828634796/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:17:14,948 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1534593231/tmp-1770474373/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1579828634796/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:17:14,949 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579828634797/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/automaton-1.11-8.jar\n",
      "2020-01-24 01:17:14,956 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579828634797/automaton-1.11-8.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:17:14,956 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579828634797/automaton-1.11-8.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/automaton-1.11-8.jar\n",
      "2020-01-24 01:17:14,956 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1534593231/tmp377703788/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1579828634797/automaton-1.11-8.jar\n",
      "2020-01-24 01:17:14,958 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579828634798/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:17:14,965 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579828634798/antlr-runtime-3.4.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:17:14,965 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579828634798/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:17:14,965 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1534593231/tmp-548517257/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1579828634798/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:17:14,967 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579828634799/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/joda-time-2.9.3.jar\n",
      "2020-01-24 01:17:14,975 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579828634799/joda-time-2.9.3.jar /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-01-24 01:17:14,975 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579828634799/joda-time-2.9.3.jar <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/joda-time-2.9.3.jar\n",
      "2020-01-24 01:17:14,975 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1534593231/tmp-1148907389/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1579828634799/joda-time-2.9.3.jar\n",
      "2020-01-24 01:17:14,976 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1579828634800/tmp686736939 <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pigsample_911933063_1579828634610\n",
      "2020-01-24 01:17:14,982 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1579828634800/tmp686736939 /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pigsample_911933063_1579828634610' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pigsample_911933063_1579828634610': Protocol error\n",
      "\n",
      "2020-01-24 01:17:14,982 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1579828634800/tmp686736939 <- /datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/pigsample_911933063_1579828634610\n",
      "2020-01-24 01:17:14,982 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1534593231/tmp686736939 as file:/tmp/hadoop-root/mapred/local/1579828634800/tmp686736939\n",
      "2020-01-24 01:17:15,043 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579828634796/pig-0.17.0-core-h2.jar\n",
      "2020-01-24 01:17:15,044 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579828634797/automaton-1.11-8.jar\n",
      "2020-01-24 01:17:15,044 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579828634798/antlr-runtime-3.4.jar\n",
      "2020-01-24 01:17:15,044 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1579828634799/joda-time-2.9.3.jar\n",
      "2020-01-24 01:17:15,044 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-01-24 01:17:15,045 [Thread-118] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-01-24 01:17:15,063 [Thread-118] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-01-24 01:17:15,066 [Thread-118] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-01-24 01:17:15,066 [Thread-118] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-24 01:17:15,067 [Thread-118] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 01:17:15,067 [Thread-118] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 01:17:15,067 [Thread-118] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-01-24 01:17:15,097 [Thread-118] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-01-24 01:17:15,097 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1414629484_0004_m_000000_0\n",
      "2020-01-24 01:17:15,123 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 01:17:15,123 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 01:17:15,124 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-24 01:17:15,126 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 525\n",
      "Input split[0]:\n",
      "   Length = 525\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-01-24 01:17:15,149 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-01-24 01:17:15,149 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-01-24 01:17:15,149 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-01-24 01:17:15,149 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-01-24 01:17:15,149 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-01-24 01:17:15,152 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-01-24 01:17:15,161 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-24 01:17:15,161 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-01-24 01:17:15,161 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-01-24 01:17:15,161 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 561; bufvoid = 104857600\n",
      "2020-01-24 01:17:15,161 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600\n",
      "2020-01-24 01:17:15,164 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-01-24 01:17:15,165 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1414629484_0004_m_000000_0 is done. And is in the process of committing\n",
      "2020-01-24 01:17:15,171 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-01-24 01:17:15,171 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1414629484_0004_m_000000_0' done.\n",
      "2020-01-24 01:17:15,171 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1414629484_0004_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=23209904\n",
      "\t\tFILE: Number of bytes written=48297885\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tMap output bytes=561\n",
      "\t\tMap output materialized bytes=603\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=18\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=396886016\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-01-24 01:17:15,171 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1414629484_0004_m_000000_0\n",
      "2020-01-24 01:17:15,171 [Thread-118] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-01-24 01:17:15,173 [Thread-118] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-01-24 01:17:15,174 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1414629484_0004_r_000000_0\n",
      "2020-01-24 01:17:15,195 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 01:17:15,195 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 01:17:15,198 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-24 01:17:15,198 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@285ad157\n",
      "2020-01-24 01:17:15,199 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-01-24 01:17:15,202 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1414629484_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-01-24 01:17:15,208 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1414629484_0004_m_000000_0 decomp: 599 len: 603 to MEMORY\n",
      "2020-01-24 01:17:15,210 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 599 bytes from map-output for attempt_local1414629484_0004_m_000000_0\n",
      "2020-01-24 01:17:15,210 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 599, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->599\n",
      "2020-01-24 01:17:15,212 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-01-24 01:17:15,213 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-24 01:17:15,213 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-01-24 01:17:15,215 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-24 01:17:15,216 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 570 bytes\n",
      "2020-01-24 01:17:15,217 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 599 bytes to disk to satisfy reduce memory limit\n",
      "2020-01-24 01:17:15,218 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 603 bytes from disk\n",
      "2020-01-24 01:17:15,218 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-01-24 01:17:15,218 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-24 01:17:15,222 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 570 bytes\n",
      "2020-01-24 01:17:15,223 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-24 01:17:15,226 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-24 01:17:15,226 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-24 01:17:15,365 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1414629484_0004_r_000000_0 is done. And is in the process of committing\n",
      "2020-01-24 01:17:15,386 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-24 01:17:15,386 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1414629484_0004_r_000000_0 is allowed to commit now\n",
      "2020-01-24 01:17:15,434 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1414629484_0004_r_000000_0' to file:/datalake/evaluacion-final-jomontoyac-master/02-pig-50/q11-10/output/_temporary/0/task_local1414629484_0004_r_000000\n",
      "2020-01-24 01:17:15,436 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-01-24 01:17:15,436 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1414629484_0004_r_000000_0' done.\n",
      "2020-01-24 01:17:15,437 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1414629484_0004_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=23211142\n",
      "\t\tFILE: Number of bytes written=48298845\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=18\n",
      "\t\tReduce shuffle bytes=603\n",
      "\t\tReduce input records=18\n",
      "\t\tReduce output records=18\n",
      "\t\tSpilled Records=18\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=396886016\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-01-24 01:17:15,438 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1414629484_0004_r_000000_0\n",
      "2020-01-24 01:17:15,438 [Thread-118] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-01-24 01:17:20,165 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:20,168 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:20,171 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:20,190 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:20,192 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:20,193 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:20,200 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:20,201 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:20,203 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:20,211 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:20,213 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-24 01:17:20,214 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "\n",
    "estilos = FOREACH u GENERATE surname AS apellido,\n",
    "                    UPPER(surname) AS mayuscula,\n",
    "                    LOWER(surname) AS minuscula\n",
    ";\n",
    "orden = ORDER estilos BY apellido ASC, mayuscula ASC, minuscula ASC;\n",
    "STORE orden INTO 'output' USING PigStorage(',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
